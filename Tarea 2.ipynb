{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2 - Procesamiento distribuido y redes neuronales profundas\n",
    "**Integrantes:** \n",
    "\n",
    "Camila Goméz Nazal -\n",
    "Ignacio Zurita Tapia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x206b19b7e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.transforms import Compose, RandomApply, RandomHorizontalFlip, Resize, RandomRotation, Lambda\n",
    "from torch.utils.data import DataLoader, Sampler, RandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from IPython.display import HTML\n",
    "from torchvision import get_image_backend\n",
    "seed = 81818 \n",
    "torch.random.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y transformación de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dataset Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "            \n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def loader(path):\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Lambda(lambda x: torch.div(x, torch.max(x)))\n",
    "brightness = Lambda(lambda x: torch.mult(x, torch.FloatTensor(x.shape[0], x.shape[1], x.shape[2]).uniform_(1.2, 1.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'ChestXRay2017/chest_xray'\n",
    "extensions = ('.jpeg')\n",
    "transform = Compose([Resize([224,224]),\n",
    "                     scale,\n",
    "                     RandomHorizontalFlip(0.5),\n",
    "                     RandomRotation([-20,20]),\n",
    "                     brightness])\n",
    "\n",
    "train = DatasetFolder(root + '/train', loader, extensions, transform)\n",
    "test = DatasetFolder(root + '/test', loader, extensions, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cantidad de muestras en cada clase en train y test:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {border-collapse:collapse;border-spacing:0;}\n",
       ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
       "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
       ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
       "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
       ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "<thead>\n",
       "  <tr>\n",
       "    <th class=\"tg-c3ow\"></th>\n",
       "    <th class=\"tg-c3ow\">Normal</th>\n",
       "    <th class=\"tg-c3ow\">NeumonÃ­a</th>\n",
       "  </tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "    <td class=\"tg-c3ow\">Train</td>\n",
       "    <td class=\"tg-c3ow\">1349</td>\n",
       "    <td class=\"tg-c3ow\">3884</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"tg-c3ow\">Test</td>\n",
       "    <td class=\"tg-c3ow\">234</td>\n",
       "    <td class=\"tg-c3ow\">390</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(filename='distribucion_datos.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas_prueba = list(zip(*test.samples))[1]\n",
    "l1=len(test.samples)\n",
    "ind_test = np.random.choice(l1, l1 )\n",
    "ind_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5232,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l =len(train.samples)\n",
    "np.random.seed(0)\n",
    "indices = np.random.choice(l, l, replace=False)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4185,)\n",
      "(1047,)\n"
     ]
    }
   ],
   "source": [
    "ind_train = indices[:int(0.8*l)]\n",
    "ind_val   = indices[int(0.8*l):]\n",
    "print(ind_train.shape)\n",
    "print(ind_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "val_samples = [train.samples[i] for i in ind_val]\n",
    "etiquetas_val  = list(zip(*val_samples))[1]\n",
    "print(etiquetas_val.count(0))\n",
    "print(etiquetas_val.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicarMuestreoDePrueba(Sampler):\n",
    "  def __init__(self, etiquetas_prueba, indices_val, etiquetas_val):\n",
    "    self.etiquetas_prueba = etiquetas_prueba\n",
    "    self.indices_val      = indices_val\n",
    "    self.etiquetas_val    = etiquetas_val\n",
    "  def __iter__(self):\n",
    "    dist_test   = self.etiquetas_prueba.count(0)/self.etiquetas_prueba.count(1)\n",
    "    dist_val    = int(self.etiquetas_val.count(1)*dist_test)\n",
    "    nro_etiq_nuevas = dist_val - self.etiquetas_val.count(0) \n",
    "    c=0\n",
    "    for i in range(len(etiquetas_val)):\n",
    "      if etiquetas_val[i]==0:\n",
    "          self.indices_val.append(self.indices_val[i])\n",
    "          c+=1\n",
    "      if c==nro_etiq_nuevas:\n",
    "        break\n",
    "    return iter(self.indices_val)\n",
    "\n",
    "c = ReplicarMuestreoDePrueba(etiquetas_prueba,list(ind_val),etiquetas_val)\n",
    "it = c.__iter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "79\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "train_sampler = SubsetRandomSampler(ind_train)\n",
    "valid_sampler = SubsetRandomSampler(list(it))\n",
    "test_sampler = RandomSampler(ind_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train.samples, batch_size=16, \n",
    "                                           sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train.samples, batch_size=16,\n",
    "                                                sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test.samples, batch_size=16, \n",
    "                                           sampler=test_sampler)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(valid_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes convolucionales profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DWSepConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=1,\n",
    "                                   padding=padding, bias=bias, groups = in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels , out_channels, kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        D = self.depthwise(x)\n",
    "        P = self.pointwise(D)\n",
    "        return P\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16DWSep, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            DWSepConv2d(64,128,kernel_size=3, padding=1),\n",
    "            DWSepConv2d(128,128,kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            DWSepConv2d(128,256,kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            DWSepConv2d(256,256,kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            DWSepConv2d(256,256,kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            DWSepConv2d(256,512,kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            DWSepConv2d(512,512,kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512,2)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\camil/.cache\\torch\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959b563bbcb04fb683b5ff0805657f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=553433881), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_name',\n",
       " '_initialize_weights',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'classifier',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'features',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretabilidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
